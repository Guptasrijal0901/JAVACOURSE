public class timendspace {
    
    
}
// amount of space or time taken up by an algorithm/code as function of input size 
// NOT the actual time taken 
// -> experimental
// -> theoretical

// In Java and Data Structures & Algorithms (DSA), time complexity refers to how the runtim
//  of an algorithm grows with respect to the size of its input. Here are some common time 
// complexities encountered in Java DSA, listed from best to worst:

// 1. **O(1) - Constant Time Complexity:**
//    - Algorithms with constant time complexity execute in the same amount of time regardless 
// of the size of the input. Examples include accessing an element in an array by 
// index or inserting/removing an element from the head of a linked list.

// 2. **O(log n) - Logarithmic Time Complexity:**
//    - Algorithms with logarithmic time complexity typically halve the problem size in each step. 
// Examples include binary search in a sorted array or operations on a balanced binary search 
// tree (like AVL tree or Red-Black tree).

// 3. **O(n) - Linear Time Complexity:**
//    - Algorithms with linear time complexity have a runtime directly proportional to the size of the input.
// Examples include iterating through an array to find a specific element or counting the occurrences of a value in a list.

// 4. **O(n log n) - Linearithmic Time Complexity:**
//    - This complexity often arises from algorithms that divide the problem 
// into smaller subproblems and then combine the results. 
// Examples include efficient sorting algorithms like Merge Sort and Heap Sort.

// 5. **O(n^2) - Quadratic Time Complexity:**
//    - Algorithms with quadratic time complexity have a runtime proportional to the square of the size of the input. 
// Examples include nested loops where each loop runs up to the size of the input,
//  like bubble sort or simple nested iterations over a 2D array.

// 6. **O(n^3) - Cubic Time Complexity:**
//    - Algorithms with cubic time complexity have a runtime proportional to the cube of the size of the input. 
// Examples include algorithms involving three nested loops, such as some matrix multiplication algorithms.

// 7. **O(2^n) - Exponential Time Complexity:**
//    - Algorithms with exponential time complexity grow very rapidly with increasing input size. 
// They are often associated with algorithms that solve problems through exhaustive search, 
// such as generating all subsets of a set or solving the Tower of Hanoi problem recursively.

// These complexities describe how algorithms perform as the size of their input increases. 
// Efficient algorithms strive for lower time complexities, 
// especially for larger inputs, to ensure reasonable execution times and scalability.
